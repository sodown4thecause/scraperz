# Prometheus configuration for Scraperz monitoring
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    monitor: 'scraperz-monitor'

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
scrape_configs:
  # Prometheus itself
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
    scrape_interval: 30s
    metrics_path: /metrics

  # Scraperz API Backend
  - job_name: 'scraperz-api'
    static_configs:
      - targets: ['api:8000']
    scrape_interval: 15s
    metrics_path: /metrics
    scrape_timeout: 10s
    honor_labels: true
    params:
      format: ['prometheus']

  # Scraperz Frontend (if metrics endpoint is available)
  - job_name: 'scraperz-frontend'
    static_configs:
      - targets: ['frontend:3000']
    scrape_interval: 30s
    metrics_path: /api/metrics
    scrape_timeout: 10s

  # PostgreSQL Database
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']
    scrape_interval: 30s
    metrics_path: /metrics
    scrape_timeout: 10s

  # Redis Cache
  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    scrape_interval: 30s
    metrics_path: /metrics
    scrape_timeout: 10s

  # Nginx Reverse Proxy
  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx:80']
    scrape_interval: 30s
    metrics_path: /nginx_status
    scrape_timeout: 10s

  # Node Exporter (if deployed)
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']
    scrape_interval: 30s
    metrics_path: /metrics
    scrape_timeout: 10s

  # cAdvisor for container metrics (if deployed)
  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']
    scrape_interval: 30s
    metrics_path: /metrics
    scrape_timeout: 10s

  # Custom application metrics
  - job_name: 'scraperz-custom-metrics'
    static_configs:
      - targets: ['api:8000']
    scrape_interval: 15s
    metrics_path: /api/metrics/custom
    scrape_timeout: 10s
    params:
      module: ['scraperz']

# Remote write configuration (for external monitoring services)
# remote_write:
#   - url: "https://your-remote-write-endpoint"
#     basic_auth:
#       username: "your-username"
#       password: "your-password"

# Remote read configuration (for external monitoring services)
# remote_read:
#   - url: "https://your-remote-read-endpoint"
#     basic_auth:
#       username: "your-username"
#       password: "your-password"